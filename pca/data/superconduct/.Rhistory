geom_point()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_line()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_histogram()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_histogram(binwidth = 1)+
xlab("k-mer length")+
ylab("count")
ggplot(histo,aes(V1,V2))+
geom_histogram(binwidth = 1)+
xlab("k-mer length")+
ylab("count")
ggplot(histo,aes(V1,V2))+
geom_bar()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
?geom_bar
ggplot(histo,aes(V1,V2))+
geom_line()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_smooth()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_smooth()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 10))
ggplot(histo,aes(V1,V2))+
geom_smooth()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 20))
ggplot(histo,aes(V1,V2))+
geom_smooth()+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
data <- read.table("/home/aither/institute-for-bioinformatics/project-3-EcoliX/assemblies/corrected_assembly-2/corrected/corr_count", sep = " ",
header = F)
histo <-data %>% slice(0:500)
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
histo <-data %>% slice(0:500)
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")
histo <-data %>% slice(0:200)
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
histo <-data %>% slice(0:200)
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 200, 10))
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 500, 25))
ggplot(histo,aes(V1,V2))+
geom_smooth(se = F)+
xlab("k-mer length")+
ylab("count")+
scale_x_continuous(breaks = seq(0, 200, 15))
?anova
?glht
data("Soils")
data("Soils")
attach(cars)
data(cars)
data(Soils)
install.packages("car")
?lm
library(cars)
library(car)
data(Soils)
data("Soils")
str(Soils)
l<-lm(pH~Depth, Soils)
summary(l)
# Базовая графика
data("mtcars")
attach(mtcars)
str(mtcars)
?mtcars
l <-anova(lm(mpg~cyl,mtcars))
View(l)
View(l)
glht(l, linfct = mcp(cyl = "Tukey"))
install.packages("multcomp")
glht(l, linfct = mcp(cyl = "Tukey"))
library(multcomp)
glht(l, linfct = mcp(cyl = "Tukey"))
l <- aov(mpg~cyl data = mtcars)
l <- aov(mpg~cyl, data = mtcars)
glht(l, linfct = mcp(cyl = "Tukey"))
View(l)
View(l)
View(l[["model"]])
summary(l)
TukeyHSD(l)
l <- aov(mpg~as.factor(cyl), data = mtcars)
summary(l)
TukeyHSD(l)
l <- lm(mpg~as.factor(cyl), data = mtcars)
TukeyHSD(l)
l.av<-aov(l)
summary(l.av)
TukeyHSD(l.av)
l <- lm(mpg~cyl, data = mtcars)
l.av<-aov(l)
TukeyHSD(l.av)
glht(l, linfct = mcp(cyl = "Tukey"))
l <-anova(lm(mpg~as.factor(cyl),mtcars))
glht(l, linfct = mcp(cyl = "Tukey"))
l <-aov(lm(mpg~as.factor(cyl),mtcars))
glht(l, linfct = mcp(cyl = "Tukey"))
l <-lm(mpg~as.factor(cyl),mtcars)
glht(l, linfct = mcp(cyl = "Tukey"))
glht(l, linfct = mcp(as.factor(cyl) = "Tukey"))
mtcars$cyl <- as.factor(mtcars$cyl)
l <-lm(mpg~cyl,mtcars)
glht(l, linfct = mcp(cyl = "Tukey"))
l.av<-aov(l)
glht(l, linfct = mcp(cyl = "Tukey"))
t<- glht(l, linfct = mcp(cyl = "Tukey"))
confint(t)
summary(t)
mtcars$cyl <- as.factor(mtcars$cyl)
l <-lm(mpg~cyl,mtcars)
t<- glht(l, linfct = mcp(cyl = "Tukey"))
summary(t)
pckages <- c('data.table', 'tidyr', 'dplyr', 'ggplot2', 'nortest', 'knitr')
for(package in pckages) {
if(!require(package, character.only = T)) {
install.packages(package, dependencies = T)
library(package)
}
}
library(data.table)
library(tidyr)
library(dplyr)
library(ggplot2)
library(nortest)
library(knitr)
input_folder <- "/home/aither/institute-for-bioinformatics/r-studio/BI_Stat_2021/anova/data/"
extension = "csv"
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), full.names = T, pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread), fill = T)
}
data <- data_import(input_folder, "csv")
View(data)
View(data)
### Check the data
unique(data)
### Check the data
unique(data$gender)
unique(data$age)
typeof(data$age)
unique(data$drug_type)
unique(data$is_relapse)
unique(data$id)
unique(data$days_in_hospital)
data[data$gender == "malle"] <- "male"
### Check the data
#replace malle with male
unique(data$gender)
View(data)
View(data)
data <- data_import(input_folder, "csv")
data$gender[data$gender == "malle"] <- "male"
typeof(data$age)
data$age[data$age == "thirty-one"] <- 31
data$age <- as.numeric(data$age)
typeof(data$age)
typeof(data$gender)
data$gender <- as.factor(data$gender)
typeof(data$gender)
unique(data$drug_type)
typeof(data$drug_type)
data$drug_type <- as.factor(data$drug_type)
type(data$days_in_hospital)
typeof(data$days_in_hospital)
knitr::opts_chunk$set(echo = TRUE)
unique(data$gender)
typeof(data$gender)
# thirty-one replace with numeric
unique(data$age)
View(data)
View(data)
# non human age
data$age[data$age > 100] <- data$age / 10
# non human age
data$age[data$age > 100] <- data$age[]/ 10
# thirty-one replace with numeric
unique(data$age)
data <- data_import(input_folder, "csv")
unique(data$gender)
data$gender[data$gender == "malle"] <- "male"
data$gender <- as.factor(data$gender)
typeof(data$gender)
# thirty-one replace with numeric
unique(data$age)
data$age[data$age == "thirty-one"] <- 31
data$age <- as.numeric(data$age)
data <- data %>% filter(age > 100) %>% mutate(age = age / 10)
# thirty-one replace with numeric
unique(data$age)
data <- data_import(input_folder, "csv")
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), full.names = T, pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread), fill = T)
}
data <- data_import(input_folder, "csv")
unique(data$gender)
# replace incorrect gender and convert to factor
data$gender[data$gender == "malle"] <- "male"
data$gender <- as.factor(data$gender)
typeof(data$gender)
# thirty-one replace with numeric
unique(data$age)
data$age[data$age == "thirty-one"] <- 31
data$age <- as.numeric(data$age)
data <- data %>% mutate(age = ifelse(age > 100, age/10, age))
# thirty-one replace with numeric
unique(data$age)
setwd("/home/aither/institute-for-bioinformatics/r-studio/BI_Stat_2021/pca/superconduct")
library(data.table)
library(tidyr)
library(dplyr)
library(ggplot2)
library(nortest)
# get files path
input_folder <- "/home/aither/institute-for-bioinformatics/r-studio/BI_Stat_2021/pca/superconduct"
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread(drop = "material")), fill = T)
}
source_data <- data_import(input_folder, "csv")
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread, drop = "material"), fill = T)
}
source_data <- data_import(input_folder, "csv")
str(source_data)
View(source_data)
View(source_data)
library(funModeling)
library(Hmisc)
library(caret)
# split data to training and evaluating parts
test_sep <- rbinom(nrow(source_data), 1, 0.5)
training_set <- source_data[test_sep == 0, ]
testing_set <- source_data[test_sep == 1, ]
basic_eda <- function(data)
{
glimpse(data)
print(status(data))
freq(data)
print(profiling_num(data))
plot_num(data)
describe(data)
}
basic_eda(training_set)
plot_num(training_set[:10])
plot_num(training_set[10])
describe(training_set)
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
cbind(lapply(files, fread, drop = "material"), fill = T)
}
source_data <- data_import(input_folder, "csv")
View(source_data)
View(source_data)
install.packages("rlist")
install.packages("rlist")
library(rlist)
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
list.cbind(lapply(files, fread, drop = "material"), fill = T)
}
source_data <- data_import(input_folder, "csv")
View(source_data)
View(source_data)
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread, drop = "material"), use.names = "check")
}
source_data <- data_import(input_folder, "csv")
# get files path
input_folder <- "/home/aither/institute-for-bioinformatics/r-studio/BI_Stat_2021/pca/superconduct"
source_data <- data_import(input_folder, "csv")
rbindlist(lapply(files, fread, drop = "material"))
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread, drop = "material"))
}
source_data <- data_import(input_folder, "csv")
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread, drop = "material"), use.names = F)
}
source_data <- data_import(input_folder, "csv")
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread, drop = "material"), use.names = T)
}
source_data <- data_import(input_folder, "csv")
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
rbindlist(lapply(files, fread, drop = "material"), use.names = F, fill = F)
}
source_data <- data_import(input_folder, "csv")
data_import <- function(input_folder, extension){
files <- list.files(paste(input_folder), pattern = paste0(".+",extension,"$"))
print(files)
bind_cols(lapply(files, fread, drop = "material"))
}
source_data <- data_import(input_folder, "csv")
View(source_data)
View(source_data)
# split data to training and evaluating parts
test_sep <- rbinom(nrow(source_data), 1, 0.5)
training_set <- source_data[test_sep == 0, ]
testing_set <- source_data[test_sep == 1, ]
basic_eda <- function(data)
{
glimpse(data)
#print(status(data))
freq(data)
print(profiling_num(data))
# plot_num(data)
# describe(data)
}
basic_eda(training_set)
clear
clear()
basic_eda(training_set)
for (i in colnames(testing_set)){
print(i)
}
for (training_set$i[1:10] in colnames(testing_set)){
print(i)
}
training_set$number_of_elements[1:2]
training_set$number_of_elements[1:10]
for (i in colnames(testing_set)){
print(training_set$i[1:10])
}
training_set$number_of_elements[1:10]
for (i in colnames(testing_set)){
print(training_set$i[1:10])
}
for (i in colnames(testing_set)){
print(training_set$paste0(i)[1:10])
}
for (i in colnames(testing_set)){
# print(training_set$paste0(i)[1:10])
print(paste0(i))
}
for (i in colnames(testing_set)){
# print(training_set$paste0(i)[1:10])
print(paste(i))
}
for (i in colnames(testing_set)){
column <- paste0(i)
print(training_set$column[1:10])
# print(paste(i))
}
for (i in colnames(testing_set)){
print(training_set[[i]][1:10])
# print(paste(i))
}
for (i in colnames(testing_set)){
print(training_set[[i]])
# print(paste(i))
}
out <-  c()
testing_set_control <- testing_set
View(testing_set)
View(training_set)
View(training_set)
View(testing_set_control)
View(testing_set_control)
# remove duplicate
ncol(source_data)
# remove duplicate
source_data <- subset(source_data, -ncol(source_data))
# remove duplicate
source_data <- subset(source_data, select = -ncol(source_data))
View(source_data)
View(source_data)
name(source_data)
names(source_data)
names(source_data)[82] <- "critical_temp"
names(source_data)
# check structure
str(source_data)
for (i in colnames(testing_set)){
if (i != "critical_temp"){
testing_set[[i]] <- (testing_set[[i]] - mean(training_set[[i]])) / sd(training_set[[i]])
}
}
View(testing_set)
View(testing_set)
# split data to training and evaluating parts
test_sep <- rbinom(nrow(source_data), 1, 0.5)
training_set <- source_data[test_sep == 0, ]
testing_set <- source_data[test_sep == 1, ]
for (i in colnames(testing_set)){
if (i != "critical_temp"){
testing_set[[i]] <- (testing_set[[i]] - mean(training_set[[i]])) / sd(training_set[[i]])
}
}
# standardize testing data using training set
testing_set_control <- testing_set
# build lm with all variables
model1 <- lm(critical_temp~., data = training_set)
summary(model1)
model2 <- lm(critical_temp~., data = testing_set)
model2 <- lm(critical_temp~., data = testing_set)
View(training_set)
View(training_set)
View(source_data)
unique(source_data$Ne)
for (i in colnames(testing_set)){
if (i != "critical_temp" && sd(training_set[[i]] != 0){
testing_set[[i]] <- (testing_set[[i]] - mean(training_set[[i]])) / sd(training_set[[i]])
}
}
for (i in colnames(testing_set)){
data_sd <- sd(training_set[[i]])
if (i != "critical_temp" && data_sd != 0){
testing_set[[i]] <- (testing_set[[i]] - mean(training_set[[i]])) / data_sd)
}
}
source_data <- data_import(input_folder, "csv")
source_data <- subset(source_data, select = -ncol(source_data))
names(source_data)
names(source_data)[82] <- "critical_temp"
test_sep <- rbinom(nrow(source_data), 1, 0.5)
training_set <- source_data[test_sep == 0, ]
testing_set <- source_data[test_sep == 1, ]
for (i in colnames(testing_set)){
data_sd <- sd(training_set[[i]])
if (i != "critical_temp" && data_sd != 0){
testing_set[[i]] <- (testing_set[[i]] - mean(training_set[[i]])) / data_sd
}
}
# build lm with all variables
model1 <- lm(critical_temp~., data = training_set)
summary(model1)
model2 <- lm(critical_temp~., data = testing_set)
summary(model2)
# PCA
pc <- prcomp(training_set[,-82], center = TRUE, scale. = TRUE)
# PCA
pc <- prcomp(training_set[,-82])
summary(pc)
summary(model1)
library(vegan)
# PCA
pc <- rda(training_set[,-82])
summary(pc)
summary(pc)
# PCA regression
model_pcr <- pcr(critical_temp~., data = training_set)
